When we're working with
large language models, often we're going to
describe in our prompt a set of rules that we want the large
language model to follow. Rules that are going
to affect its output and essentially program
the large language model. One of the things that
we're going to want to do, we're going to want to say, here are the rules, now apply them to an input that I'm going
to provide later. One of the challenges is, how do we get the large
language model not to immediately respond
to all of our rules? If we have a flipped
interaction, for example, sometimes when we flip the
interaction and we say, ask us questions, it'll generate 10 or 20 questions all at once. A way to do is basically
a simple way that we can get the large
language model to listen to what we're saying, acknowledge it, and then
wait for input from us. Now, we can do this with
the ask for input pattern. The idea behind this
is we want to get the large language
model to listen to the rules and then ask us for the input to
apply the rules to. When we're talking about asking questions in a
flipped interaction, we might want to describe the rules for asking
the question, and then we just wanted
to ask one question. So we just want to
get one question out. If we're describing rules
for alternative approaches, we might want to say,
here are the rules. You're always going to create
alternative approaches to whatever asked you to do, but just ask me now for the first task to create
alternative approaches for, we don't want you to go and
have a big response to it. What we see is that that's
not always the case. Let's take a look
at this example. Now, in a prior video, I introduced the alternative
approaches pattern, and when you saw me
use this pattern, it worked really effectively
because I was actually combining it with the
ask for input pattern. I'm going to show you
what it looks like when I don't combine it with the
ask for input pattern. I went and I said, whenever I ask you to write a prompt for me to
accomplish a task, list what the task is, list the alternative approaches
for creating the task, and then write a prompt for
yourself for each approach. I'm asking in ChatGPT, give me a bunch of alternatives
for prompting you, ChatGPT, to solve the task. This is going back
to the earlier idea where I showed how
we can actually use ChatGPT to generate prompts for itself to help us
with prompt engineering. What I do is I use this, but I'm taking away something important that I'm going
to show you in a minute. What it does is
ChatGPT responds, it says certainly, but
then it dreams up a task. It says, here are three
alternatives for completing the task organizing
a cluttered desk. I'm not interested in the task organized
a cluttered desk. It just responded to
my initial prompt, which was, create alternative
approaches for a task. It dreamed up a task
and then dreamed up its own approaches
for that task. Now, I'm not interested in this, so now I've got my
conversation and it's got all this extra stuff in it
that I don't care about. I had to wait for
it to generate it. If I was trying to create some interactive experience
that had some consistency, this would not be helpful. What I can do is I can apply
the ask for input pattern. Then the idea behind this is we just do one simple thing, and at the end of the prompt, we tell the large language model to ask for the next input. In this case we say, ask
me for the first task. The very last thing we do, we describe all the rules, or whatever it is that
we want in our prompt, and then the last thing
we do is we say, now, ask me for the first task, ask me for the first idea, ask me for the first
thing you want me to generate a story
about, whatever it is. But it's a way that we can cut off the large language
model and tell it, don't go generate
a bunch of stuff. I'm glad that you can do that, but what I want you to do
is I want you to stop right here and asked me
what I want to do. It's a way of forcing the large language
model to basically turn the control back over to the user and let them
decide what to do next. Now, like all prompt patterns, when we're dealing with
a larger language model, it is somewhat
stochastic or random. It means it's not
always going to do exactly the same
thing every time. It may not work 100
percent of the time, but this works very, very
reliably to just say, ask me for the first input or whatever it is at the end of the prompt because it clues the large language
model and it needs to stop. If we look at the
comparison of the output, it's actually much more focused. We see, in this case it says, certainly, let's begin. What is the first task you
would like me to create alternative approaches
and prompts for? Rather than this much longer
saying that it generated before that was not really helpful to
what we were doing, so it cuts it off. Notice it's the same input, but it cut it off. It's told that,
look, you need to stop right here and you need to wait for my input.