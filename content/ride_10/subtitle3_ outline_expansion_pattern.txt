There's a limit
to how big we can go with the large
language models. They fundamentally
have a limit to the size of the input
we can give them, so how big of a prompt we
can give them or how long our conversation can be and
they can still remember it, and there's just a limitation on how much output they
can generate at once. Now, it's inevitable that these language models are going to keep getting
bigger and bigger and we're going to
be able to give them more and more input and get more and more output from them. But more than likely,
everybody is going to face some limitation on
how big we can go. Now the way that we
work around that is we're typically
generating pieces, we've generated a piece of the
solution, then we take it. You can imagine, if you're
trying to generate a book, you can't just tell
ChatGPT at this point, "Go and generate a book for me." It's not going to do it,
it's going to tell you, "Well, I have to stop my
end point at some point." Similarly, you
can't just give it 50,000 pages at this
point and dump it into ChatGPT and ask it
to give you an answer or 100,000 pages or
a million pages. There's always
going to be a limit probably on the amount
of information. We need a way to work with
it in smaller pieces, but still be able to put all
the pieces back together. One of the ways that we can do that is by building an outline of what we're trying
to put together and we can build
the outline out, we can build it to the level of granularity that we want, and then we can start filling in the pieces once we've gotten enough detail into our outline, and then we can go and generate individual pieces
and we can know where they all fit together. This is an effective
way of using it to generate the pieces. Now this is basically
putting a plan together. This same approach works
for all kinds of things. It could be software, anywhere where we can go and have this outline-like
structure, and then if we generate
something that fits the outline or the
plan at that point, then we can go and work with it. Now we're going to look at
a specific pattern that can help us generate the
outlines and work with them. This is called the outline
expansion pattern. The idea is we want
to make it really easy to generate
outlines and continue to expand them down to the
level of granularity that we need in order to build the individual pieces then be
able to put them together. One of the reasons
that outlines are a really helpful tool
when we're building bigger bodies of work
with a tool like ChatGPT, is that we can always take parts of the
outline and copy and paste or reintroduce
them into the prompt to give the large language model
context about what we want. With ChatGPT, for example, we can generate an outline and
then we can copy and paste a portion of the outline into our prompt and say
within this context, where you are in the outline, now fill in the content
for this and don't repeat anything that
would have come before in the
outline and in fact, you can refer to
the other parts of the outline wherever
you're going to talk about a topic that was discussed previously or maybe
we want to have forward references where we can provide at the high
level outline and say, "Wherever you are going
to need to talk about a topic that's going
to be discussed later, you can provide a
forward reference to where it is and the outline." You can do similar types
of things with software or whatever the bigger thing
is that you're building. Now, this works
well when we have a structure that's an amenable to this
outline-based plan. Now sometimes we have plans, or structures, or designs where everything crosses over and
you can't easily do this. It doesn't work to express
it as an outline and express the plan
and in those cases, it just doesn't work. But many problems, we can build out in this outline-like
fashion and then we can use cutting and pasting from the outline to provide
the appropriate context. Building outlines can be a
really powerful thing for us. We're going to look at and build with the outline
expansion pattern. Here's what we say,
we're going to say, "Act as an outline
expander," and notice, I'm starting to introduce
multiple patterns here. I'm basically introducing
the persona pattern. "Generate a bullet point outline based on the
input that I give you and then ask me for the bullet point
you should expand on." We're telling it you're
going to generate the outline and then
you're going to expand on anything that
I ask you to expand on, create a new outline for the
bullet point that I select. At the end, ask me for what bullet point
to expand the next. Notice, I'm using the tail
generation pattern as well, and then I'm using the
ask for input pattern. I'm putting a lot
of things together into this prompt and I say, ask me for what to outline. What we see is it says, "Sure, I'd be happy to
help you with that." I say, let's write an outline for writing effective
prompts for ChatGPT. What we see is that
ChatGPT generates this outline and it's an
interesting outline introduction to ChatGPT, understanding the
importance of prompts, tips for writing
effective prompts. yada, yada, yada. A lot
of good things there. Then I decide, let's go and expand on three
from the outline. If we look back here, three was tips for writing
effective prompts. I thought let's go ahead
and expand the outline there and explore
this a little more. Then it picks up from
three and it expands on tips for writing expected prompts and
gives us a new outline. We build and using this pattern, we can rapidly fill in and
outline, and probably, there are going to be tools to support us in this very soon, or plugins to support
us in this very soon to where we don't have to remember all the
pieces of the outline. With this, I would probably
just manually have a document whereas it was
generating the pieces, I would go and look
and say, here's three. I'll paste three
and its expansion now and you can easily
fit the parts together. This is one of the nice things about the outline approach, is that it's really obvious how all the pieces fit together. I know that 3.1
goes underneath 3, so it's self describing
in terms of the assembly. If I generate a piece
of an outline here, I've expanded three, I know exactly where that goes, how it fits together
in the overall whole. Then I go and say, well, this idea of experimenting with different prompt styles,
that looks interesting. Maybe I should go and expand
that further in the outline. I basically say 3.2, and now it goes and expands
the outline around 3.2. You see how we've got
a simple pattern, and we now can go and rapidly create an outline and keep expanding into the
level of detail, and because of it's using
this outline structure, it's really easy to fit all of the individual pieces
back together. As long as we have limitations
on how much input, how big of a prompt we can give, and how much output
we can get it once, we're always going to
be looking for ways to generate things in pieces and
know how they fit together. We want the pieces to be really obvious on how to assemble
them and we always want to make sure that we
have a clear structure or set of guidelines for each individual piece so
that we can assemble them. You can imagine if this part of the outline depends on knowledge of what was covered in a different
part of the outline, then we would need to make sure that that was introduced
into the prompt. We just said 3.2, but if we had an idea that maybe the conversation
had gotten so long that what was in item
1 had been forgotten, we might want to go
and just cut and paste the outline
underneath one back into the prompt and then say expand 3.2 because we know 3.2 was
just previously generated, but that would help give it the knowledge of what had come
before and make sure that what it put into 3.2 was consistent with
what had been done earlier in the
overall structure. Similarly, if it needs
to make sure that 3.2 was cohesive with
what's going to come later, we would want to put
in those pieces. One of the things
we have to think about is even if
this outline style, when we do this, it will work. But we always have
to think about, does it still have the
context to make sure the individual
pieces are cohesive even if they fit into the
outline at this point, we want to make sure it
doesn't do something that breaks something
somewhere else. This is a problem, a fundamental challenge that we're always working with and
prompt engineering when we're building from pieces. How do we build the pieces so that they're standalone,
self-contained, but can be assembled into the overall whole.
We see this again. We just expand 3.5, which was setting
the tone and style, and we get this very
rapid expansion in creation of a sophisticated
outline now that we can use to write text for a bigger project to be able
to try to write software. There's all analogies or
analogues to the outline, the master structure
where we start with a certain level of detail, then we pick some
piece of it and we expand the level of detail. Then we may pick a piece of that and we may
expand the detail. Then we may move back up to another bullet pant
point in the outline and expand the level of detail. We can be moving up and
down in the outline, we can be going up
to the top level, or we can be going down to
the really detailed things, and we can expand wherever
we want and keep a map of the overall picture that
we can use to build individual pieces and make sure that we can assemble them. But also as we build pieces, that we can make sure that ChatGPT has the
relevant information. This section of the
outline, for example, in the prompt that
it needs in order to reason about or generate whatever it's going
to produce next.