When we're having a
long conversation with a large language model, sometimes we'll run
into the challenge that the large language model will forget the rules of the game. It'll forget what we're
trying to accomplish. What is the task that
we're working on? One of the things we
need is a way to remind the large language model,
what are we doing? We'd like it to remind
itself if possible. The way that we can do
that is by using what we call the tail
generation pattern. The idea behind this
is that we're going to generate a tail, an end to the output that the large language
model produces that will help remind
it what we're doing. The tail is going to always be generated at the
end of its output. The tail will remind the large language model what
the rules of the game are. We're going to see
this in the context of combining the tail pattern with the alternative
approaches pattern and with the
ask-for-input pattern. We're going to put all
these things together and we're going to see how this
is a really useful thing. Generating a tail on
our conversation using a tail generation
pattern is really effective in maintaining
our conversation longer and maintaining the rules and the knowledge of
our rules longer. I've actually used this several times and I haven't
talked about it, but I'm going to show
you what it does. This is the prompt
that I used in the alternative approaches
pattern discussion. I'm asking ChatGPT to generate a set of prompts
to solve a particular task. I'm asking ChatGPT to help
us with prompt engineering. I'm going to give it
a task and it's going to generate possible prompts that we could use to perform
that task with ChatGPT. Now, if I do this over and over, and I keep saying anytime
I ask you for a prompt, you should go back and generate multiple alternatives for it, the problem I'm going to run into is that eventually
it's going to forget that it's supposed
to generate a bunch of alternatives and
then it's supposed to be generating prompts. I need a way that
keeps re-introducing that rule into the conversation
to keep it alive longer. One way I can help do that
is with the tail generation. This is the tail that's
being generated. I have the prompt and I say, when you are done, ask me for the next prompt to
create alternatives for it. I'm adding this on. I'm saying when you're done
at the end of your output, you're going to ask me for the next prompt to create
alternatives for it. Notice what I'm doing. I'm actually using the
ask for input pattern. I'm saying at the end of the
output that you produce, you're going to ask me
for the next input. You're going to ask me for
the next task to accomplish. I'm telling it, you're
going to ask me for the next prompt to
create alternatives for. I'm also re-introducing
the rules of the game. I'm describing what
the purpose of the input is that I'm
going to be giving it and what it's
supposed to do with it. I'm making sure that
this shows up at the end of the output that the large language model
is going to produce. I've defined the
rules and I'm saying, at the end of what you do, you're going to re-introduce this rule by basically asking me for the next input to create
alternative prompts for. Let's see what happens. I add this tail on and so
I'm generating a tail. I'm using the tail
generation pattern, and I say write a prompt for ChatGPT to
automatically detect questions and a chain
of emails and summarize everyone's opinions
on the question as bullet points beneath
each question. I've given it the task.
Here's what I want you to write me some
possible prompts for. I would give it the instruction. It's now going to write
the prompts and it generates a bunch
of prompts for me. Now I've got all these
alternative prompts. Then the last thing it
does is it generates the tail just like I said. It says, please
let me know if you have another task for which you would like me
to write a prompt and create alternative
approaches for us. Right here, it's created
a tail on its output. It's at the very end. It says, please let me know
if you have another task for which you'd like me to write a prompt and create
alternative approaches. You notice that the
sentence that it's created encompasses
a lot of the rules, it encompasses enough of the information about
what it's trying to accomplish that we don't have to worry as much that it's
going to forget the rules. Then I go and I give
it another task. I say write a prompt to evaluate different prompts for
summarizing the questions, and it goes through
and it generates all the prompts
which we saw before, and then at the end, it
generates the tail again. Please let me know if you have another task for which you'd like me to write a prompt and create alternative
approaches. We've got it to re-introduce
the task again. Now if we went on and
we put in a new prompt, it still will remember
what the context is. If we went in and we had
back-and-forth without this, at some point, it's going to forget the rules of the game. It's going to say, what
am I supposed to do? Or it's going to forget
to generate alternatives, or it's going to
do something else. But by continually
re-introducing the rules of the game as
this tail on the output, then every time we go
to send it a new input, just recently we had the
rules of the game and gave it the context that needs
to accomplish the task. The tail generation approach is really useful when we're going to have a
longer conversation, where we're going to try
to program something. We're going to give it a
bunch of rules upfront and then we're going to have a
whole bunch of interactions. We don't want it to forget
the rules or the contexts. Now it doesn't have to be rules, it could be anything that
we think that needs to be re-introduced over and over
into the conversation. What we do is we just make sure that at the end of the output, we ask it to put in
whatever that tail is. It could be asking
for the next input, it could be asking for some other additional
information that could be re-described
in the rules, it could be whatever
you want it to be, but it's like a little nugget, a little tail that we're
going to attach to that output to remind the
large language model, here's what we've been talking
about and give yourself a little hint about it at the very end before we
go on to the next task.