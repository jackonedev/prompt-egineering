Large language models are unlikely,
at least in the near term to give you an exact and
repeatable answer every single time. There's always going to be the possibility
they do something a little bit unexpected and this is by design and
can be a really good thing. Now, a lot of what we're going to be doing
in prompt engineering is trying to deal with the fact that large language models
have some unpredictability to them. And we want to sort of constrain that
unpredictability, we want to mold it and shape it and work with it in
a way that's helpful to us. Now, what I mean by this is that
there's always some randomness, some ability to generate new and different
ideas each time you put a prompt in. And this can be really good sometimes. If we're writing fiction and
we want a lot of different ideas, a lot of different storylines,
a lot of different characters. And each time we ask for
new data or ask for a new output, we get something completely new and
unique, then it's really good. On the other hand, if we're trying to have
the large language model do some type of reasoning on a system, we may not want
it to have a lot of variation and what it gives us out. For example, if we want a yes or
a no answer. We don't want it to say yes, sometimes,
no, sometimes, and then suddenly decide just say, well, maybe not because here are
these other things that I'd like to tell you about why it's hard to determine and
goes on on this tirade for a paragraph or two about why it can't exactly
give us the exact answer. Sometimes we just want a yes or
a no without any explanation and we can't always get that easily. So, a lot of the prompt engineering
techniques are going to be dealing with this. Now, I'm going to just show you
a quick sample of the randomness. The fact that the same input
is not necessarily going to give us this exactly
the same output every time. And I want you to remember this when
we go through this course because I'm going to show you a lot of
different techniques to try to get the large language
model to do certain things. And sometimes they're going to work really
well and sometimes they won't work. But what these techniques will typically
give you is they will give you something that's more reliable that works most
of the time or a lot of the time but isn't guaranteed to
work every single time. Now, this is an important point. We're always going to have
some randomness here. We're always going to have some
unknown and we have to accept that and deal with that. So, I asked ChatGPT I said,
how many birds are outside my house? And it says as an AI language model, I don't have the capability to
perceive the physical world. And he goes on and then it says, if
you're interested in finding out how many birds are outside of your house,
you can go outside and observe the area yourself, you might also
considering setting up a bird feeder. Okay, well, that was an interesting one. Let's see if we ask it again what it says. So, now we're going to go and get a
different answer out of it and says, well, I can't see what's going
outside your house. I don't have access to cameras. I only do text processing. And then it says, you could go outside and
observe the area yourself or you could set up a camera or
other monitoring device to record. Get the number of birds, availability
of food, shelter, and presence. And so, now,
we've gotten something different. And what we don't have anymore is
this advice to set up a bird feeder. If we went and ran this again,
we're probably also going to get yet another example. It's probably going to have
some similar characteristics. It's still going and saying, hey,
I don't have the ability to do that. It's running some of its things that it's
sort of standard text that it tells you. But then it's saying, hey, if you're interested in how
you could try observing the area or to capture images of the area, you can
then count the number of birds you see. Additionally, you could consider
setting up bird feeders or bird baths. So, we're getting a similar
output each time, but it's not exactly the same output. And so, this is a fairly constrained
set of outputs for this question. We're still getting some similar type of
things each time, but we're not getting exactly the same thing and
that's always going to be an issue for us. So know that when you're
developing prompts, a lot of what you're dealing with is
the fact that there is variation. Now, if I wanted it to give
me an exact number and I was using a prompt like this,
this is obviously not going to work. We're not going to get an exact number
of birds outside of my house with this prompt. Now, we might need to
be able to go back and give it additional information
that could help it decide.