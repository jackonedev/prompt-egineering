What are large language
models exactly? What do they do?
How do they work? Now I'm not going to go into
the full details of this, but I want to give you
just enough about how they work that will help you in thinking through
designing prompts. There's a couple of things
to know about them that will be useful when
you're designing prompts. Now, though, fundamental thing that
you want to know about these large language models is basically what they're
doing is they're taking your input and they're trying
to generate the next word. Then they'll take that
word that they generate, they'll add it to you what
you originally gave it, and they'll try to
generate the next word. This is a way to think of it. Now there's a lot more
detail than this, but think of it basically
is it's trying to generate word by word, the response to your input, whatever your prompt is, they're just going to try
to generate word by word. The next word that's
going to be in the output until it gets to a point that it thinks
is generated enough. Then the last word is basically going to be
the equivalent of stop. But it's not going to be
something you're going to see. What it's doing is basically
producing words or tokens, these agree to respond
to your prompt. What we're trying to do with large language
models is we're trying to produce prompts
that then cause it word by word to
produce an output. Now, I want to show
you a little bit about this and give you
some intuition of it. If I go and I write, Mary had a little and we stop right there. If you're familiar with
the nursery rhyme, Mary had a little lamb, it's fleece was white as snow. I'm giving it a prompt. If I say Mary had a little, it's going and then
completing it, it starts from my
last statement, Mary had a little
and it's giving the, predicting the next
word, which is lamb. It's fleece was white as snow. Everywhere that Mary went
the lamb was sure to go, it followed her to
school one day, which was against the rule
that made the children laugh in play to see
a lamb at school. And so the teacher
turned it out, but still it lingered near and it goes on and
on until it stops. Now you notice what it's
doing is it's my prompt triggered it to produce
the next word which was Mary had a little
was my prompt. The next word was lamb. If I go and I say roses are red. What does Chat GPT do? It says violets are blue, sugar is sweet and so were you. It says this is a classic
point is often used to express affection or
admiration for someone. But the key thing
to note is it's doing a next word prediction. I said roses are red and
it's picking up where I stopped and predicting the
next word which is violet's. It's an adding that in
and saying roses are red violets and it's
predicting are. Then going back, adding that in, it says roses are red, violets are, and it's
predicting blue. It's doing this over and over. It does really sophisticated
incredible things. But underneath the hood, when it was trained and created, basically what was done
was a large portion of the text and other things
on the Internet were taken. It was taught basically
over and over again. It was given a series of words and it tried to
predict the next word, except that it was given a paragraph of text
from the Internet. They would show it
part of the sentence and then ask it
to try to predict the next word in the sentence. When it got it wrong,
they would go and tweak the model is what they
call these things, large language models, and their large because
they were trained on so much data and they have so many different
parameters to them. They are these large
language models. What they're doing is they've learned patterns
from our language, our human language that was
out there on the Internet. They've basically
learned the idea of given what came
before in the text. Try to predict the next word and then if I take that word
and I add it back in, try to predict the next word. They train these models
to get really good at looking at the context
of the information. Now if you think about it, it has a lot of conduct. It's tapping into a
pattern that had seen, I said Mary had a little
and it says lamb. It could have been
Mary had a little bit of peanut butter on her shirt. But it's learned context. That's part of what
makes it work. It could be roses are red,
daffodils are yellow. But it's learned this context. That's a part of
the piece of this, is it pays attention to words and uses that knowledge
of the contexts. It's paying attention
to different words that have come before that are
in the current sentence. It's paying attention
to their relationships. It's using that
contextual knowledge to try to predict
the next word and then it's taking the
word that it produced, putting it back into the output and trying to
produce the next word. This is the basis of things. Now this will be
helpful to know when we start thinking about the
patterns of our prompts. When we think about
conversations. When we think about what
we can do to tap into this fundamental concept of
predicting the next word. Now, one of the things to know with these models is they
are rapidly evolving. We're seeing a lot in
the news about ChatGPT, but there's lots of competing
models that are coming out. Probably by the time you're
watching this video, there will be even more that I'm not going to mention
or talk about because they didn't exist today when I started
talking about it. ChatGPT is certainly out there. There's a new version GPT-4. They're models like LLaMa. There are variations
on LLaMa like Alpaca. There's all different
models that are coming out and they're
rapidly evolving. More than likely, the discipline of prompt engineering and what you're learning, some parts of this are going
to be hopefully timeless, but some parts of it
will probably evolve and adapt as the different
capabilities of these models evolve. Now one of the things
you'll want to do is always have that openness
to experimentation, to creativity, and to
in trying things out. Remember with these tools, we can rapidly prototype. We can rapidly explore
things and try things out, and so we want to
always tap into that. Now, one thing to note
is that a lot of times these tools will
produce output that is not the same every time. Now it's possible that we could get the same output every time. In certain cases, like roses are red and now we get
something different. Then if we went in
and we did it again, we get something different. Now notice that initially we got something that
was what we expected, but each time we're getting
some variation on this. This is something
else that's useful to know is these models aren't designed to do exactly the
same thing every time. There's inherent randomness or variation in what they produce. This is something
you need to know about when you're
using the models. It's really powerful and useful if you use
them the right way. If you aren't using the models
the right way or you're trying to fit them in for a task that they're not good for, you're going to have to
do a lot of work to deal with this fundamental
aspect of it. But it's also an aspect that makes you want to
think about this as, you should never
expect these outputs to be perfect necessarily
on the first try. It's a tool that can help you get an
output that you want, but it's not necessarily
perfect on the first try. There may be errors,
there may be variation, and you need to build that into the processes and the other things that you
build around the tool. If you're going to use
it in your business, know that it may not give you exactly the same
output every time. Now there's ways to try to help limit what it does and
try to guarantee that, but it's not
guaranteed to do that, and so you want to know that. You want to know there's
some randomness, there's some variation which
can be grateful when we're writing prose with this because we don't get
exactly the same text every time or else we would all have exactly the same outputs and we wouldn't be able to
explore and try things. Knowing that is an
helpful thing to realize. Now is shined on a vast
amount of data that came from the
Internet knowing that it's knowledge is based on the time that the training
data was collected. In the case of ChatGPT, it's cutoff around 2021. Newer ones have more
up-to-date knowledge bases, but they're always going to be behind in what they
were trained on. They were taught to
predict the next word, and they learned from that idea of predicting
the next word. They learn to predict
the next word in the context of a lot of different domains be it
speech-language pathology or programming, or be it
about creating recipes, whatever it is that their knowledge that
they were trained on and the patterns that they learned cutoff at some date. When we want to introduce and reason or work with
new knowledge, we're always going
to have to provide that as part of our prompt, as part of our input
into the conversation, is that whatever
additional information they need in order to reason, they're not necessarily
continually updating. They can't retrain these things
necessarily all the time. Now it may change at some point, the technologies may change, but right now today
know that when you need new additional information that wasn't publicly available
on the Internet, you're probably going to need to provide it in the prompt. Now those are some of
the key things that you'll need to know as we go forward in this course in order to help you write
more effective prompts.