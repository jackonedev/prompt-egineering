Large language models can
actually do some planning, which is an interesting ability. They can actually
go through and take patterns and with
few-shot examples and they can learn what the next action should be
given a particular situation. But I'm giving you this example not because
they are limited to coming up with planning
in the sense of actions or doing
sentiment analysis, but I want you to expand your mind on what's
possible with few-shot prompting and see
it as a technique that can be taken and adapted to
all kinds of situations. We've seen how we can use few-shot prompting when we're
doing sentiment analysis, now we're going to do something
very different with it. We're going to take a look at this example where
we're describing different situations
with driving a car. In the first one, we see, situation: I'm traveling 60
miles per hour and I see the brake lights on the
car in front of me come on and the action is
we're going to break. Again, we've got
our first example in our few-shot examples. Situation: I've just entered the highway from
an on-ramp and I'm traveling 30 miles per
hour, action: accelerate. We're teaching the large language model
that it's going to be given a situation
and it needs to decide what the car should do. Situation: a deer has
darted out in front of my car while I'm traveling 15 miles per hour and the
road has a large shoulder, action: break and swerve
into the shoulder. Situation: I'm backing out of a parking spot and I
see the reverse lights illuminate on the car
behind me and then we prompt it with action. We leave off at the
end of our prompt with something that indicates
a large language model. We want it to decide what the action is and
what do we see it do? It actually says,
stop and wait for the car to back out
before proceeding and it's making a
sensible decision about what the action should be. Now, I don't think we
should go and build self-driving cars with
few-shot prompting. I don't think we're going
to get there with that, but I do want to show
you that we don't have to think just
with a narrow, rigid box of classify something. We can actually have complex tasks that we're
having to perform. Now sentiment analysis
is a complex task, but this is also a
very complex task, it's in a different vein. I want us to think very creatively about how we
can use few-shot prompts. Now again, one of the
things that we're getting is we're getting some
constraints on our output. It's learning what the
output should look like. Now, I'm going to then go and do something
else interesting. I'm going to show you an
interesting capability of large language models. One of the things
that can be done to use one large language
model to teach another one, which is an interesting
capability. I'm going to say, please provide more examples, and then I'm going to
prompt it with situation. It's going to start generating additional situations
and actions. It's learned from our pattern, the types of things that we're describing and the types of actions and now it's going to go and
generate more example. It says, you are driving in heavy rain and notice that
the road ahead is flooded, so this is the continuation
of our situation. Then it says, action: slow down and cautiously drive
through the flooded area, watching out for
other vehicles and avoiding sudden movements
or changes in directions. I would actually
disagree with this. I'm not sure that it's smart to drive through
a flooded area. That's probably questionable
decision-making, which again, just reminds you
that you need to own the output of a large
language model and check it. Situation: you are driving
on a two lane road and a car is approaching you from the opposite direction
with their high beams on, action: dim your headlights to low beams to avoid blinding
the oncoming driver. But you notice the
interesting thing about this is it's giving us some rich situations and
possibly appropriate actions. I'm not sure I agree
with the flooded one, but we're generating
different examples of situations and what to do and they look very similar
to what we produced before. One thing that's
interesting is we can actually take examples like this and then curate them
and have a human edit them, and then provide them back to a large language model either later as additional examples
for our few-shot examples. Once we've had a human look at them and curate
them a little bit, maybe clean them up, maybe we don't want that one on flooding because we don't
think that's a good idea, so we actually say, well, you shouldn't drive
across flooding, we spell the rules. But you can imagine that
the level of effort to create the initial
examples right here is much higher than the
effort to go through and generate subsequent
examples which we can then go and
hand edit and curate, so we can quickly build
up these examples, both in order to generate an output
right now that we want, but also to generate
examples that we can later give back to the same
large language model, or that we could go and give to another large language
model to teach it. In fact, some people have
actually gone and done this. They've taken output
from ChatGPT, for example, and
they've taken it into another large
language model, like Facebook's LLaMA, and used the output from ChatGPT to improve
the outputs of LLaMA. This is another
interesting capability, is that large language models, through these few-shot examples, they can generate few-shot
examples for other models. The other thing I just want
to go back to is this is a very different task and
style than we had before. We have a situation
and then we have an action that's
being predicted. We can have all kinds
of interesting things, anywhere where we can have a pattern that we can describe, a set of examples that show the input and what we
want the outcome to be, and we can also show things
that have intermediate steps, which we'll look at
in another video.