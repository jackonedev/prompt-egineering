Let's talk intuitively about what a prompt
is doing and how the patterns and the prompt sort of tap into the
capabilities of a large language model. Sort of, I think looking at some
examples will help to give you a sense of how your prompts are really affecting
and eliciting different behaviors from the other reliant large language
model that you're interacting with. So, let's take a look at this example. I want to start off by talking about
pattern, patterns really important. Remember as we talked about, large language models are trained
to basically predict the next word, they're constantly trying to predict
the next word based on what came before. So you give it a sentence and
it's trying to predict the next word and then it's taking that and adding it and
trying to predict the next word and over and over and over. And so, it was trained on large pieces of
the internet trying to predict the next sentence. So one of the things that it's learning to
do is to recognize patterns that tell it what the next word should be,
that's basically what it's doing. Now, this is a really simple
example of this concept. I'm going to tell Chat GPT
complete this story and I start with Mary had a little and
I stop now, if you know the nursery rhyme,
it's Mary had a little lamb. It's fleece was white as snow. And you can imagine that this story
showed up over, and over, and over, and over in the data
that Chat GPT was trained on. So when I say Mary had a little,
that is a very powerful pattern that Chat GPT has seen many,
many, many times. And so it immediately tries to pick
up with lamb, it's fleece as white as snow and everywhere that Mary went,
the lamb was sure to go. So that pattern was seen so
many times that Chat GPT, when I put in the first part of it,
it immediately responds with the next part of the sentence,
it knows where to pick up. So one thing we have to think about is,
if we know the right patterns, if we can tap into things that the model has
been trained on and seen over, and over, and over again, we will be more likely
to not only get a consistent response. So we're going to consistently get a
particular completion of Mary had a little because it's been seen so
many times in the training data, we get more consistency. But we're also going to more likely get a
particular sort of ability to tap into it, to unlock it. If we want a particular behavior, we want to have the right
pattern that we're tapping into. Now, let's look at what happens
if we change the pattern a bit. And so I say, rather than Mary had
a little, I say complete this story, a girl named Mary had a microscopic. Now, this isn't the pattern that
it was trained on anymore, right? And it says a girl named Mary had
a microscopic friend named Max. Max was so small, you could only
see him through a microscope. Despite his size,
he had a big personality and was always eager to go
on adventures with Mary. One day, Mary decided to take
Max on a trip to the local pond. She carefully placed him on a lily pad. Now, one of the interesting things is you
can imagine that when you start talking about microscopic. You can think about, there's probably
descriptions of going to a pond and doing science with a class of students. I mean, I almost have a vision of it,
reading stories about students getting samples of pond water and
looking at them under a microscope. But the important thing is you
notice that Mary created a very, very specific response,
whereas a girl named Mary had a microscopic creates
a much different response. And then if we go and rerun this,
we get something completely different, pet named Max, Max was a tiny creature
that lived in a small glass jar. And so, this pattern isn't as strong. There are words in this
pattern that are strong and sort of give context that
help to shape the story, but the pattern itself is not
as strong as Mary had a little. So doing it again whereas the other
story changed completely, I'm still getting the same completion
with this, I'm still getting lamb, it's fleece was as white as snow. So every time I'm getting a very
consistent response to this pattern. So one of the things to think about
when you're writing a pattern or writing a prompt is what
patterns do I have in my prompt. And what patterns will that probably tap into that the large language
model was trained on? Now, if there's a very strong
pattern in the prompt, you're more likely to get
a response to that pattern. On the other hand, if that's not a pattern
that it was trained on, it's not as clear, then you're going to have
other things that are going to matter like specific words. So microscopic,
that word is fundamentally going to change the behavior of this prompt
because it's such a strong word. A girl named Mary is sort of generic, there were probably lots of
stories with a girl named Mary. But microscopic, it has all of this
feeling and implications to it. And that's going to then influence
the large language models output, specific words alone because of
the patterns around those words. Like microscopic is always going to
be talked about in the context of small things probably, or maybe in
terms of things like in this case, a small creature that
lived in a glass jar. That word itself has a strong sort of
pattern of other words that are coming around it but it's not as strong
as the pattern, Mary had a little. Now, one thing to note is that
when you're writing prompts, you want to be really specific or you want
to provide enough detail in your words. That the large language model will know
the right level of detail to put into the output. So if your words are very generic and
high level, then you're more likely to get an output
that is also generic and high level. So if you look at this example,
I say discuss Vanderbilt University and I get a very generic sort of response. It's a private research university
located in Nashville, Tennessee, founded in 1873 by Cornelius Vanderbilt,
ranking other things. Now, if I want something really specific,
I need to make sure that Chat GPT has the right words and
context in order to answer my question. So Chat GPT is not a mind reader,
you have to give it the context, you have to give it the words that
are going to elicit the right response. If I go back and I say discuss Vanderbilt
University with respect to Kirkland Hall, it's a specific building on campus,
then it changes the output, I get a much more specific output. I get Vanderbilt University is a private
research university located in Nashville, Tennessee. Now we notice we're getting this
fairly consistently, both of them. So that's probably pattern or information
that the model was trained on and saw over and over again on different web pages for
Vanderbilt and different documents. And then it queues in on the Kirkland Hall
and it starts discussing Kirkland Hall. It's one of the most iconic buildings
on Vanderbilt University campus, named after James H.Kirkland. It then talks about Kirkland Hall,
Kirkland Hall, Kirkland Hall. And so,
we've now completely changed the output. Now, even though we had
shared a common beginning, we got a much more targeted output. And the key to this was is that we added
in specificity into our prompt about what we wanted, the details. So if you think about asking it to write
something or to analyze something, it's always helpful when
you say with respect to. And give it very specific words,
or names, or things that you want it to then
use to trigger the output. Because what we see is this Kirkland Hall
is a very powerful word that then gets woven into the whole discussion,
it's a powerful name of a building. If we just say generically at a high
level, we don't use specific words, we don't use a specific context. We're going to get very generic stuff and
this is probably stuff that if you go and look at descriptions on Wikipedia,
descriptions on Vanderbilt's web pages, this is like the most common types
of information that you see. So in order to break out of
the mold of what is common, you need to inject the more specific
ideas that you want in the output or you need to inject patterns that will
help tap into those more specific things. So this is an important aspect in that,
if you just use it and you ask it generic questions,
you're going to get generic answers. If you ask it average questions and average things,
you will get average answers. To really use it powerfully,
you have to use your own creativity and thought to get specific about details
aspects of what you want discussed. And think about what are the right
patterns to put into your prompt in order to trigger
the behavior that you want, like we saw in this
Mary had a little lamb. Or we might want to do the opposite, we
might know that we're going to get a very generic response because certain
things have been seen a lot. And so, we need to come up with tricks,
or patterns, or specific words that will help break us out of those patterns
that we're seeing in the trading data so that we can get something
that's more of what we want. So we don't want to be trapped into
the completion of Mary had a little lamb. So we go and add specific words like
microscopic and a girl named Mary so that it's not so strong, so that we're
not directly getting into that pattern. So just changing the wording can
help us escape the patterns or get into the patterns
depending on what we want. And then when we get output, the more
generic our language, typically, the more generic the output, the more specific our
language, the more specific the output. And if we want certain
things in that output, we need to make sure we
have specific words and phrases that will tap into the specific
things that we want in the output. Now, one of the other things is we're
talking about output but in the sense of a query, like if I have specific words,
it'll pull in the right information. One of the things we can also do is our
prompt itself is a pattern that the large language model is learning from and
it can also tailor the output. So as we've seen in examples
before we can go in and do different things to
try to affect the output. So for example, I might go in and actually
let's change this up a little bit. Let's say, title, and
we could say title of article, and then we could say author, and then we could say summary,
and we could go in and give it something that it can look at and
respond to. So now what I've done is I've gone and provided it some some structure. Now it hasn't followed
my structure exactly and this is actually a failing in my prompt. I hasn't quite thought of the right
structure, but I've gotten pretty close. So I went and influenced the output and
the structure of the output by giving it additional
pattern in my prompt itself. So one thing we can do is we can tap into
patterns in order to influence the output. Another thing we can
do is we can go in and use specific words and
phrases to kind of be a query across or to basically collect learned information
that's inside of the train model. Another thing we can do is we can go
in and we can provide information or basically new pattern that
then influences the output. So in this case, I provided
the structure of what I wanted and it somewhat followed it, and I could
probably go and rerun this thing and get something a little better and
in this case, I do. So this will be another thing that we can
do is we can use our prompt to create sort of new patterns that it's
trying to follow in the output. So the prompt itself can
introduce new patterns or tap into them in some respects. So this is kind of creating pattern
that it then is responding to as well. So when you're writing prompts,
it's really important to think through this concept that it's trying
to predict the next word, and it's doing that based on patterns
it's learned in the past. And patterns that are in
the language of our prompt and patterns that are based on
the word choice that we have, patterns that are based on
the sort of textual organization. And so, those patterns can help
us get a consistent response. If we have a really strong pattern that
always produces a particular next token or next word, then we can rely on that. If we don't want that behavior, we can
try to change our phrasing our words, we get out of that trap. If we want to make sure certain
information is pulled in, we need to create specific words or
patterns that are more likely to have been seen in the context of
that information that we want. If we want more generic information,
then we probably need to give it more generic language or tell it that we want
it to be more generic in some respect. And then finally, if we want
the output to look a certain way, we need to give it sort of
a sense of pattern in the output. We need to tell it about the structure,
we need to give it words and patterns in our prompt that will
be likely to influence the output. So you can imagine seeing title and author on an article was
something that was fairly common. So if I put title and
author in this way into my prompt, then it's more likely going to want to
go and create title and author again and sort of replicating the pattern
of what I'm showing here. So that should give you some intuition
about how all of this works and some things to think about when you're
going and structuring your prompts, picking words for them,
picking the patterns in your language. And picking the things that you
want to go into the output, how you structure and
kind of explain the output to it.